{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9322c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "382997c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>content</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2861071620726465</td>\n",
       "      <td>🔥 𝐍𝐚𝐧𝐨𝐛𝐲𝐭𝐞 𝐓𝐮𝐲𝐞̂̉𝐧 𝐃𝐮̣𝐧𝐠 REMOTE ANDROID Develo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2860805674086393</td>\n",
       "      <td>Công ty IT vừa thành lập nửa năm cần tuyển key...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2860731854093775</td>\n",
       "      <td>Hôm nay trời nắng, cty mình cần gấp 2 bạn fron...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2860903027409991</td>\n",
       "      <td>[PICON TECHNOLOGY - CHÚNG MÌNH TÌM UX/UI DESIG...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2861061440727483</td>\n",
       "      <td>ĐN- bên em dự án lớn tuyển dev C/C++Software E...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            post_id                                            content images\n",
       "0  2861071620726465  🔥 𝐍𝐚𝐧𝐨𝐛𝐲𝐭𝐞 𝐓𝐮𝐲𝐞̂̉𝐧 𝐃𝐮̣𝐧𝐠 REMOTE ANDROID Develo...     []\n",
       "1  2860805674086393  Công ty IT vừa thành lập nửa năm cần tuyển key...     []\n",
       "2  2860731854093775  Hôm nay trời nắng, cty mình cần gấp 2 bạn fron...     []\n",
       "3  2860903027409991  [PICON TECHNOLOGY - CHÚNG MÌNH TÌM UX/UI DESIG...     []\n",
       "4  2861061440727483  ĐN- bên em dự án lớn tuyển dev C/C++Software E...     []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuyendung = pd.read_csv(\"output1.csv\")\n",
    "tuyendung.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e21e516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     🔥 𝐍𝐚𝐧𝐨𝐛𝐲𝐭𝐞 𝐓𝐮𝐲𝐞̂̉𝐧 𝐃𝐮̣𝐧𝐠 REMOTE ANDROID Develo...\n",
       "1     Công ty IT vừa thành lập nửa năm cần tuyển key...\n",
       "2     Hôm nay trời nắng, cty mình cần gấp 2 bạn fron...\n",
       "3     [PICON TECHNOLOGY - CHÚNG MÌNH TÌM UX/UI DESIG...\n",
       "4     ĐN- bên em dự án lớn tuyển dev C/C++Software E...\n",
       "5     (TP Huế) Tuyển\\nC/C++ or Python or Swift dev ~...\n",
       "6     Đà Nẵng tuyển\\nIT COMTOR\\nTiếng Nhật N1, CÓ kn...\n",
       "7     1. Job Remote Fulltime - Senior Front-End Deve...\n",
       "8     Đà Nẵng tìm gấp\\nPHP/ C++ WITH GOOD ENG\\nlevel...\n",
       "9     [AVEPOINT – DANANG]\\n“Dính cứng ngắc” với hệ t...\n",
       "10    Mục tiêu R500 sẵn sàng, welcome 500 ae về Rikk...\n",
       "11    Ở đây chúng mình có \"Evizi, Job xịn và Lương c...\n",
       "12    💥CÔNG TY ZIMAW - TUYỂN DỤNG NHỀU VỊ TRÍ💥💥\\nLIN...\n",
       "13    ĐÀ NẴNG OPEN JOB PHP/ JAVA/ TESTER/ REACTJS 🤤🤤...\n",
       "14    Mình cần Xây Đội DEV lập trình back-end , chuy...\n",
       "15    TÌM KIẾM 50 NHÂN SỰ MỚI OB TRONG T3 NÀY\\nVới m...\n",
       "16    Các anh chị nhân sự ơi, có thực sự cần tuyển d...\n",
       "17    Để có thêm \" kiến thức, trải nghiệm, kinh nghi...\n",
       "18    “Anh sẽ yêu em cho đến khi anh còn thở!” Dune ...\n",
       "19    DỰ ÁN MỚI ĐANG ĐỢI CÁC BẠN ONBOARD!\\n ⭐️Junior...\n",
       "20    [GLORY SOFTWARE VIETNAM - ĐÀ NẴNG]\\nDự án được...\n",
       "21    Angular 3 năm kinh nghiệm nhảy vào đây, em nhậ...\n",
       "22    Năm nay Huệ vẫn focus chính cho thị trường Nhậ...\n",
       "23    ️🔥🔥🔥Hot! Hot! Hot!\\n[ĐN] IRTECH đang tìm người...\n",
       "24    🌼 JOB BOARD_ĐÀ NẴNG 🌼\\n-----------------------...\n",
       "25    Hè sắp đến rồi các bạn sinh viên đã là member ...\n",
       "26    Fsoft ĐN open vị trí 2 BACKEND (Python & .NET)...\n",
       "27    Năm nay IT tuyển dụng sôi động nhỉ , từ Cam, p...\n",
       "28    [Đà Nẵng] 💕Quẹt trái, quẹt phải, chi bằng quẹt...\n",
       "29    LG ĐÀ NẴNG CHIÊU MỘ NHÂN TÀI IT\\n☀️ Sở hữu mức...\n",
       "30    🎌 IT Bridge Engineer (Japanese speaking) || Hả...\n",
       "31    Chào cả nhà, hiện tại em đang làm việc ở SG, c...\n",
       "32    💼 Yspace Đang Tìm Bạn! Những người 🚀\\nĐam mê c...\n",
       "33    🌼 8/3 nhà nhà tặng hoa thì Yspace tặng Job 🌼\\n...\n",
       "34    Xin chào cả nhà ạ. Green Technology.STC mở rộn...\n",
       "35    Mình cần tuyển thêm 1 bạn trợ lí để làm tik to...\n",
       "36    FPT SOFTWARE DA NANG\\nTiếp tục tuyển job Fresh...\n",
       "37    FSoft DN tuyển 10 bạn Fresher Java, yêu cầu có...\n",
       "38    [Axon Active] Ở đây có job JAVA siêu xịn 🌟\\n‼️...\n",
       "39    NALS cần lắm sự hội tụ của các Middle RoRs, .N...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = tuyendung['content']\n",
    "content.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858b168",
   "metadata": {},
   "source": [
    "# Vẽ biểu đồ ngôn ngữ thông dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb1391a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m language_counts \u001b[38;5;241m=\u001b[39m {language: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m programming_languages}\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m tuyendung[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 6\u001b[0m     words \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mw+\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     words \u001b[38;5;241m=\u001b[39m [word\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m programming_languages:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\re.py:240\u001b[0m, in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m \n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "programming_languages = ['Python', 'Java', 'C++', 'JavaScript', 'Ruby', 'Swift', 'Go', 'PHP', 'C#', 'TypeScript', 'R', 'Kotlin', 'Scala', 'Perl', 'HTML', 'CSS']\n",
    "\n",
    "language_counts = {language: 0 for language in programming_languages}\n",
    "\n",
    "for content in tuyendung['content']:\n",
    "    words = re.findall(r'\\b\\w+\\b', content)\n",
    "    words = [word.lower() for word in words]\n",
    "    for language in programming_languages:\n",
    "        if language.lower() in words:\n",
    "            language_counts[language] += 1\n",
    "\n",
    "language_counts_df = pd.DataFrame.from_dict(language_counts, orient='index', columns=['Count'])\n",
    "\n",
    "language_counts_df = language_counts_df.sort_values(by='Count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "language_counts_df.plot(kind='bar', color='skyblue')\n",
    "plt.title('Programming Languages Usage')\n",
    "plt.xlabel('Programming Language')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae535ace",
   "metadata": {},
   "source": [
    "# Tạo thuộc tính mới từ text -> Vị trí làm việc, email , ngôn ngữ yêu cầu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28065896",
   "metadata": {},
   "source": [
    "### Location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21123d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_locations_file(locations_file):\n",
    "    with open(locations_file, 'r', encoding='utf-8') as file:\n",
    "        locations = [line.strip() for line in file]\n",
    "    return locations\n",
    "\n",
    "def add_location_to_csv(input_csv, locations_file, output_csv):\n",
    "    locations = read_locations_file(locations_file)\n",
    "    output_data = []\n",
    "\n",
    "    with open(input_csv, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            content = row['content'].lower()  \n",
    "            location = find_location(content, locations)\n",
    "            row['location'] = location\n",
    "            output_data.append(row)\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['post_id', 'content', 'location', 'images']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in output_data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "def find_location(content, locations):\n",
    "    for location in locations:\n",
    "        if location.lower() in content:\n",
    "            return location\n",
    "    return 'Unknown'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2489d528",
   "metadata": {},
   "source": [
    "### Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email(text):\n",
    "    pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b'\n",
    "    emails = re.findall(pattern, text)\n",
    "    return emails[0] if emails else 'Unknown'\n",
    "\n",
    "def update_analyzed_data_with_email(input_csv_file, output_csv_file):\n",
    "    with open(input_csv_file, 'r', encoding='utf-8') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    for row in rows:\n",
    "        row['email'] = extract_email(row['content'])\n",
    "\n",
    "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        fieldnames = ['post_id', 'content', 'images', 'email', 'location']\n",
    "        writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326af1b4",
   "metadata": {},
   "source": [
    "# Ngôn ngữ lập trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aba4dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addProgrammingLanguagesToCSV(input_csv, programming_languages_file, output_csv):\n",
    "    with open(input_csv, 'r', newline='', encoding='utf-8') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    with open(programming_languages_file, 'r', encoding='utf-8') as lang_file:\n",
    "        programming_languages = [line.strip() for line in lang_file]\n",
    "\n",
    "    fieldnames = reader.fieldnames + programming_languages\n",
    "\n",
    "    for row in rows:\n",
    "        content = row['content']\n",
    "        for lang in programming_languages:\n",
    "            if re.search(r'\\b{}\\b'.format(re.escape(lang)), content, flags=re.IGNORECASE):\n",
    "                row[lang] = '1'\n",
    "            else:\n",
    "                row[lang] = '0'\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940af40",
   "metadata": {},
   "source": [
    "# Trình độ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82ef75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLevelToCSV(input_csv, level_file, output_csv):\n",
    "    with open(input_csv, 'r', newline='', encoding='utf-8') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    with open(level_file, 'r', encoding='utf-8') as lang_file:\n",
    "        levels = [line.strip() for line in lang_file]\n",
    "\n",
    "    fieldnames = reader.fieldnames + levels\n",
    "\n",
    "    for row in rows:\n",
    "        content = row['content']\n",
    "        for lang in levels:\n",
    "            if re.search(r'\\b{}\\b'.format(re.escape(lang)), content, flags=re.IGNORECASE):\n",
    "                row[lang] = '1'\n",
    "            else:\n",
    "                row[lang] = '0'\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06adc97",
   "metadata": {},
   "source": [
    "# Ngoại ngữ yêu cầu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4e6db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLanguagesRequirementToCSV(input_csv, languages_file, output_csv):\n",
    "    with open(input_csv, 'r', newline='', encoding='utf-8') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    with open(languages_file, 'r', encoding='utf-8') as lang_file:\n",
    "        languages= [line.strip() for line in lang_file]\n",
    "\n",
    "    fieldnames = reader.fieldnames + languages\n",
    "\n",
    "    for row in rows:\n",
    "        content = row['content']\n",
    "        for lang in languages:\n",
    "            if re.search(r'\\b{}\\b'.format(re.escape(lang)), content, flags=re.IGNORECASE):\n",
    "                row[lang] = '1'\n",
    "            else:\n",
    "                row[lang] = '0'\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec9422",
   "metadata": {},
   "source": [
    "# Mảng chuyên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff105687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMajorsToCSV(input_csv, major_file, output_csv):\n",
    "    with open(input_csv, 'r', newline='', encoding='utf-8') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    with open(major_file, 'r', encoding='utf-8') as lang_file:\n",
    "        majors= [line.strip() for line in lang_file]\n",
    "\n",
    "    fieldnames = reader.fieldnames + majors\n",
    "    for row in rows:\n",
    "        content = row['content']\n",
    "        for lang in majors:\n",
    "            if re.search(r'\\b{}\\b'.format(re.escape(lang)), content, flags=re.IGNORECASE):\n",
    "                row[lang] = '1'\n",
    "            else:\n",
    "                row[lang] = '0'\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461fcdb",
   "metadata": {},
   "source": [
    "# Lương"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2e783b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary(text):\n",
    "    patterns = [\n",
    "    r'(?:up\\s*to|upto\\s*)?(?P<min_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*-\\s*(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*M',\n",
    "    r'(?:up\\s*to|upto\\s*)?(?P<min_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*-\\s*(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*tr',\n",
    "    r'(?:up\\s*to|upto\\s*)?(?P<min_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*triệu\\s*-\\s*(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*triệu',\n",
    "    r'(?P<min_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*-\\s*(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)M',\n",
    "    r'(?P<min_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*-\\s*(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)tr',\n",
    "    r'(?P<min_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*triệu\\s*-\\s*(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*triệu',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*million\\s*-\\s*(?P<max_salary>\\d{1,2})\\s*million\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*M\\s*-\\s*(?P<max_salary>\\d{1,2})\\s*m\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*triệu\\s*-\\s*(?P<max_salary>\\d{1,2})\\s*triệu\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*-\\s*(?P<max_salary>\\d{1,2})\\s*m\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*-\\s*(?P<max_salary>\\d{1,2})\\s*tr\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*-\\s*(?P<max_salary>\\d{1,2})\\s*triệu\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*-\\s*(?P<max_salary>\\d{1,2})\\s*đ\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*-\\s*(?P<max_salary>\\d{1,2})\\s*đồng\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*tr\\s*-\\s*(?P<max_salary>\\d{1,2})\\s*tr\\b',\n",
    "    r'(?P<min_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*-\\s*(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*VND',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*triệu\\s*đến\\s*(?P<max_salary>\\d{1,2})\\s*triệu\\b',\n",
    "    r'(?P<min_salary>\\d{1,2}(?:\\.\\d{3})?)VND\\s*-\\s*(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)VND',\n",
    "    r'(?P<min_salary>\\d{1,2})m\\s*-(?P<max_salary>\\d{1,2})m\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*đến\\s*(?P<max_salary>\\d{1,2})\\s*triệu\\b',\n",
    "    r'\\b(?P<min_salary>\\d{1,2})\\s*đến\\s*(?P<max_salary>\\d{1,2})\\s*tr\\b',\n",
    "    r'(?P<min_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*-\\s*(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)',\n",
    "    r'(?:up\\s*to\\s*)?(?P<max_salary>\\d{1,2}(?:\\.\\d{3})?)\\s*M',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text.lower())\n",
    "        if matches:\n",
    "            if len(matches[0]) == 2:  # Nếu có cả minSalary và maxSalary\n",
    "                min_salary = float(matches[0][0]) * 1000000 if 'triệu' in pattern else float(matches[0][0]) * 1000\n",
    "                max_salary = float(matches[0][1]) * 1000000 if 'triệu' in pattern else float(matches[0][1]) * 1000\n",
    "                avg_salary = (min_salary + max_salary) / 2\n",
    "                return min_salary, max_salary, avg_salary\n",
    "            elif len(matches[0]) == 1:  # Nếu chỉ có maxSalary\n",
    "                max_salary = float(matches[0][0]) * 1000000 if 'triệu' in pattern else float(matches[0][0]) * 1000\n",
    "                return 'Unknown', max_salary, 'Unknown'\n",
    "\n",
    "# Nếu không tìm thấy, trả về giá trị mặc định\n",
    "    return 'Unknown', 'Unknown', 'Unknown'\n",
    "\n",
    "\n",
    "\n",
    "def add_salary_columns(input_csv_file, output_csv_file):\n",
    "    with open(input_csv_file, 'r', encoding='utf-8') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    for row in rows:\n",
    "        min_salary, max_salary, avg_salary = extract_salary(row['content'])\n",
    "        row['minSalary'] = min_salary\n",
    "        row['maxSalary'] = max_salary\n",
    "        row['avgSalary'] = avg_salary\n",
    "\n",
    "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        fieldnames = ['post_id', 'content', 'images', 'email', 'location', 'minSalary', 'maxSalary', 'avgSalary']\n",
    "        writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc9c2a",
   "metadata": {},
   "source": [
    "# Năm kinh nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e996f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experience(text):\n",
    "    pattern = r'(\\d+)\\s*(?=\\s*năm)'\n",
    "    experience = re.findall(pattern, text)\n",
    "    return experience[0] if experience else 'Unknown'\n",
    "def update_analyzed_data_with_experience(input_csv_file, output_csv_file):\n",
    "    with open(input_csv_file, 'r', encoding='utf-8') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    for row in rows:\n",
    "        row['experience'] = extract_experience(row['content'].lower())\n",
    "\n",
    "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        fieldnames = ['post_id', 'content', 'images', 'email', 'location','minSalary', 'maxSalary', 'avgSalary' ,'experience']\n",
    "        writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e7a7b",
   "metadata": {},
   "source": [
    "# Trích điện thoại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "17480019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phonenumber(text):\n",
    "    pattern = r'(?<!\\d)(?:0|\\+84|84)(?:\\d(?:\\s|\\.)?){9,10}\\b'\n",
    "    phone_numbers = re.findall(pattern, text)\n",
    "    return phone_numbers[0] if phone_numbers else 'Unknown'\n",
    "def addPhonenumberToCSV(input_csv_file, output_csv_file):\n",
    "    with open(input_csv_file, 'r', encoding='utf-8') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    for row in rows:\n",
    "        row['phonenumber'] = extract_phonenumber(row['content'])\n",
    "\n",
    "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        fieldnames = ['post_id', 'content', 'images', 'email', 'location', 'minSalary', 'maxSalary', 'avgSalary', 'experience', 'phonenumber']\n",
    "        writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "4127fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = 'output1.csv'  \n",
    "locations_file = './Vietnamese-data/Vietnam GIS data/Vnlocations.txt' \n",
    "programming_languages_file = './Vietnamese-data/ProgramLanguages.txt'\n",
    "languages_requirement_file = './Vietnamese-data/ForeginLanguagues'\n",
    "majors_file = './Vietnamese-data/Major.txt'\n",
    "level_file = './Vietnamese-data/Level.txt'\n",
    "output_csv = 'analyzed_data.csv'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "1d1604ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_location_to_csv(input_csv, locations_file, output_csv)\n",
    "update_analyzed_data_with_email(output_csv, output_csv)\n",
    "add_salary_columns(output_csv,output_csv)\n",
    "update_analyzed_data_with_experience(output_csv,output_csv)\n",
    "addPhonenumberToCSV(output_csv,output_csv)\n",
    "addProgrammingLanguagesToCSV(output_csv, programming_languages_file, output_csv)\n",
    "addLevelToCSV(output_csv,level_file,output_csv)\n",
    "addLanguagesRequirementToCSV(output_csv,languages_requirement_file,output_csv)\n",
    "addMajorsToCSV(output_csv,majors_file,output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a7207",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d5b3a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name =' \\[(?!HN\\]|HCM\\])(.*?)\\]|.*CÔNG TY TNHH.*|(.*?)(?=TUYỂN DỤNG|tuyển dụng|recruit)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e22551fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches = re.findall(company_name , tuyendung[0].)\n",
    "# matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "013a1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary =  r'Mức lương:\\s*(.*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e40826b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recruitment1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[331], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m matches \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(salary, \u001b[43mrecruitment1\u001b[49m)\n\u001b[0;32m      2\u001b[0m matches\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recruitment1' is not defined"
     ]
    }
   ],
   "source": [
    "matches = re.findall(salary, recruitment1)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'F'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
